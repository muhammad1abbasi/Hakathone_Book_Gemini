---
id: chapter-03-action
title: "Chapter 3: Executing LLM-Planned Actions"
sidebar_position: 3
description: Connecting LLM-generated robot plans to the ROS 2 Action infrastructure for robust execution and feedback.
---

## Chapter 3: Executing LLM-Planned Actions

### Summary
This chapter focuses on the critical link between the abstract task plans generated by an LLM and the concrete physical actions of a robot. You will learn how to translate an LLM's output (e.g., a sequence of high-level steps) into executable ROS 2 Actions, Services, and Topics. We will build a "Robot Executive" node that orchestrates these low-level ROS 2 commands, providing feedback to the LLM (or directly to the user) and handling potential failures during execution.

### Why This Chapter Matters
An LLM can generate a perfect plan, but if the robot can't execute it reliably, the system is useless. This chapter closes the loop, showing you how to turn linguistic understanding into real-world physical changes. It emphasizes robust execution, error handling, and the ability to provide meaningful feedback, which are all crucial for trust and effectiveness in human-robot interaction.

### Real-World Robotics Use-Cases
- **Complex Assembly Tasks**: An LLM plans the sequence of robotic arm movements to assemble a product, and the Robot Executive executes each grasp, move, and place action.
- **Dynamic Environment Navigation**: An LLM plans a route through a crowded room, and the executive issues navigation goals and handles re-planning if new obstacles appear.
- **Human-Robot Handoffs**: An LLM plans the interaction flow for handing an object to a human, and the executive controls the gripper and arm to perform the precise motion.

### Skills Students Will Build
- Designing a "Robot Executive" node that interprets LLM output.
- Converting LLM-generated high-level commands into ROS 2 Action goals or Service requests.
- Monitoring the execution of ROS 2 Actions and handling their feedback.
- Implementing basic error recovery strategies for failed robot actions.
- Providing status updates and feedback from the robot's actions back to the user or LLM.
- Understanding the challenges of grounding language in the physical world.
