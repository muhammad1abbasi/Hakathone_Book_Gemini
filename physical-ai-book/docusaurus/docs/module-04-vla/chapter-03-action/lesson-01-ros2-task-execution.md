--- 
id: lesson-01-ros2-task-execution
title: "Lesson 1: The Robot Executive - Orchestrating ROS 2"
sidebar_position: 1
description: Building a Python node that takes LLM-generated action sequences and executes them as ROS 2 commands.
---

### Lesson Objective
To develop a **Robot Executive** node that can interpret a structured JSON action sequence (generated by an LLM) and translate it into actual ROS 2 calls (Topics, Services, Actions).

### Prerequisites
- Completion of Module 4, Chapter 2 (Language).
- Solid understanding of ROS 2 communication patterns (Topics, Services, Actions).

### Concept Explanation
The LLM has given us a beautiful JSON list of actions the robot needs to perform. Now, we need a "conductor" to make the orchestra play. This conductor is our **Robot Executive** node. Its job is to:

1.  **Receive Action Sequences**: It subscribes to a topic (or receives a service call) where the LLM's action sequences are published.
2.  **Iterate and Execute**: It loops through each action in the sequence.
3.  **Map to ROS 2 Primitives**: For each action, it determines if it needs to publish a Topic message, call a Service, or send a Goal to an Action Server.
4.  **Handle Asynchronicity**: For Actions, it needs to manage the asynchronous nature (sending a goal, listening for feedback and result).
5.  **Report Status**: It reports back to the LLM (or a user interface) on the success or failure of each action.

This Executive acts as a crucial middleware, abstracting away the low-level ROS 2 communication details from the LLM, and presenting a clean "action interface" to the AI planner.

### Real-World Analogy
Imagine you've given a detailed to-do list to a personal assistant.
- **Your to-do list** is the LLM-generated action sequence.
- **The personal assistant** is our Robot Executive.
- For each item on the list ("Call the florist", "Email John", "Book a flight"), the assistant knows *how* to perform that task (using the phone, sending an email, using a travel website).
- They execute each task in order, provide you updates, and report when the list is complete or if there was a problem.

### Hands-On Task
**Task**: Create a simple Robot Executive node that can execute `move_base` and `gripper_control` actions.

1.  **Create Executive Node**: Create a Python script named `robot_executive.py` in your `ros2_ws/src` directory.
2.  **Write the Code**: Copy the Python code from the example below. This executive will subscribe to a topic `robot_commands` (where the LLM output would typically be published) and execute simple movement and gripper actions.
3.  **Run the Executive**:
    ```bash
    source /opt/ros/humble/setup.bash
    cd ros2_ws/src
    python3 robot_executive.py
    ```
4.  **Publish Commands**: Open a second terminal and publish a sample action sequence (e.g., to move the robot forward).
    ```bash
    source /opt/ros/humble/setup.bash
    ros2 topic pub --once /robot_commands std_msgs/msg/String 
    "{data: '{\"type\": \"action_sequence\", \"actions\": [{\"name\": \"move_base\", \"parameters\": {\"direction\": \"forward\", \"distance_meters\": 1.0}}] }'}"
    ```
5.  **Observe**: In the executive's terminal, you will see it parse the command and simulate executing the actions.

### Python + ROS 2 Code Example
```python
# robot_executive.py

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from geometry_msgs.msg import Twist # For move_base
import json
import time

class RobotExecutive(Node):
    def __init__(self):
        super().__init__('robot_executive')
        self.get_logger().info('Robot Executive node has been started.')

        # Subscriber for LLM-generated commands
        self.command_subscription = self.create_subscription(
            String,
            'robot_commands',
            self.command_callback,
            10)
        self.command_subscription  # prevent unused variable warning

        # Publishers for robot control
        self.cmd_vel_publisher = self.create_publisher(Twist, 'cmd_vel', 10)
        
        # Action client for long-running tasks (e.g., actual movement)
        # For this lesson, we'll simulate. In future lessons, connect to actual Action Servers.

    def command_callback(self, msg):
        self.get_logger().info(f'Received command: "{msg.data}"')
        
        try:
            command_data = json.loads(msg.data)
            if command_data.get("type") == "action_sequence":
                actions = command_data.get("actions", [])
                self.execute_action_sequence(actions)
            elif command_data.get("type") == "clarification_needed":
                self.get_logger().warn(f"LLM needs clarification: {command_data.get('question')}")
                # Here, you would send this back to a UI or the human
            else:
                self.get_logger().error(f"Unknown command type: {command_data.get('type')}")

        except json.JSONDecodeError:
            self.get_logger().error(f"Failed to parse JSON command: {msg.data}")
        except Exception as e:
            self.get_logger().error(f"Error processing command: {e}")

    def execute_action_sequence(self, actions: list):
        self.get_logger().info(f"Starting action sequence with {len(actions)} actions.")
        for action in actions:
            action_name = action.get("name")
            parameters = action.get("parameters", {})
            self.get_logger().info(f"Executing action: {action_name} with params: {parameters}")
            
            if action_name == "move_base":
                self._execute_move_base(parameters)
            elif action_name == "gripper_control":
                self._execute_gripper_control(parameters)
            elif action_name == "report_status":
                self._execute_report_status(parameters)
            else:
                self.get_logger().warn(f"Action '{action_name}' not implemented by executive.")
            
            time.sleep(1) # Simulate action taking time

        self.get_logger().info("Action sequence completed.")

    def _execute_move_base(self, params: dict):
        direction = params.get("direction", "forward")
        distance = params.get("distance_meters", 0.0)
        
        twist_msg = Twist()
        if direction == "forward":
            twist_msg.linear.x = 0.5 # m/s
        elif direction == "backward":
            twist_msg.linear.x = -0.5
        elif direction == "left":
            twist_msg.angular.z = 0.5 # rad/s
        elif direction == "right":
            twist_msg.angular.z = -0.5
        
        self.get_logger().info(f"Moving robot {direction} for {distance} meters (simulated).")
        # In a real system, you'd send an Action Goal or continuously publish Twist messages
        # Here we simulate by just publishing once and waiting.
        self.cmd_vel_publisher.publish(twist_msg)
        time.sleep(distance * 2) # Simulate taking time to move
        twist_msg.linear.x = 0.0 # Stop
        twist_msg.angular.z = 0.0 # Stop
        self.cmd_vel_publisher.publish(twist_msg)


    def _execute_gripper_control(self, params: dict):
        command = params.get("command")
        self.get_logger().info(f"Simulating gripper {command}.")
        # In a real system, this would call a Service or publish to a Topic for the gripper.
        
def _execute_report_status(self, params: dict):
        status_type = params.get("status_type")
        self.get_logger().info(f"Simulating reporting {status_type} status.")


def main(args=None):
    rclpy.init(args=args)
    robot_executive = RobotExecutive()
    rclpy.spin(robot_executive)
    robot_executive.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Common Mistakes & Debugging Tips
- **Mistake**: The Executive doesn't correctly parse the JSON from the LLM. Ensure your `json.loads()` calls are robust and that the LLM is consistently outputting the expected format.
- **Mistake**: Not mapping LLM-generated actions to actual ROS 2 primitives. The LLM doesn't know ROS 2 directly; it's up to the Executive to translate.
- **Tip**: Implement logging (`self.get_logger().info()`) generously in your Executive. This helps trace the flow of control and diagnose where an action sequence might be failing.

### Mini Assessment
1.  What is the main role of the "Robot Executive" node?
    a) To transcribe speech.
    b) To generate LLM prompts.
    c) To interpret LLM action sequences and execute them as ROS 2 commands.
2.  If an LLM outputs an action sequence in JSON, what Python function is used by the Executive to convert this string into a Python dictionary/list?
    a) `json.dumps()`
    b) `json.loads()`
    c) `str.split()`
3.  Why does the Executive need to manage asynchronicity for ROS 2 Actions?
    a) Because Actions are very fast.
    b) Actions are long-running tasks, and the Executive needs to monitor their progress without blocking.
    c) Because Actions require a graphical interface.
4.  If the LLM generates an action `turn_around(degrees=180)`, but your robot only has `move_base(direction, distance)`, what is the Executive's responsibility?
    a) To report an error immediately to the user.
    b) To try and map `turn_around` to a sequence of `move_base` commands, or report that the action is not supported.
    c) To tell the LLM to only generate `move_base` actions.
5.  What ROS 2 primitive would typically be used to send continuous velocity commands to a robot?
    a) Service call.
    b) Topic publication.
    c) Action goal.
